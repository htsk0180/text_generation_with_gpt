{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSvuS_ITs_1c"
      },
      "source": [
        "# KerasNLP ile sıfırdan GPT metni oluşturma\n",
        "\n",
        "Metin üretimi için bir mini GPT modeli eğitmek üzere KerasNLP'yi kullanacağız."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B86jwQQvs_1g"
      },
      "source": [
        "## Giriş\n",
        "\n",
        "Bu örnekte, küçük bir generative oluşturmak için KerasNLP'yi kullanacağız.\n",
        "GPT, girilen metin bilgisinden sonra gelişmiş metin oluşturmanıza izin veren Transformer tabanlı bir modeldir.\n",
        "\n",
        "Modelimizi [simplebooks-92](https://arxiv.org/abs/1911.12391) corpusu üzerinde eğiteceğiz. Bir kaç farklı romandan oluşan bir veri kümesidir.\n",
        "\n",
        "Bu örnek,\n",
        "[Minyatür GPT ile metin oluşturma](https://keras.io/examples/generative/text_generation_with_miniature_gpt/)\n",
        "KerasNLP soyutlamaları kavramlarını birleştirir. KerasNLP tokenizasyonunun, katmanlarının ve\n",
        "ölçümler eğitimi basitleştirir.\n",
        "\n",
        "Bu örneği google colab üzerinde çalıştırıyorsan çalışma türünü GPU olarak ayarlamalısın.\n",
        "\n",
        "Sonra ie KerasNLP yi indirelim.\n",
        "`pip install keras-nlp`\n",
        "\n",
        "`KerasNLP`, kullanıcıları tüm geliştirme döngüleri boyunca destekleyen doğal bir dil işleme kitaplığıdır. İş akışlarımız, kutudan çıkar çıkmaz kullanıldığında son teknoloji önceden ayarlanmış ağırlıklara ve mimarilere sahip olan ve daha fazla kontrol gerektiğinde kolayca özelleştirilebilen modüler bileşenlerden oluşturulmuştur. Geliştiricilerin TensorFlow ekosistemini kullanarak kolay üretim bekleyebilmesi için tüm iş akışları için grafik içi hesaplamayı vurguluyoruz.\n",
        "\n",
        "Bu kitaplık, çekirdek Keras API'sinin bir uzantısıdır."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade protobuf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Ub7GwOv_FO",
        "outputId": "97d19b8f-cd53-447c-d26e-1ef84ce7b3f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (4.22.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-nlp"
      ],
      "metadata": {
        "id": "te_BuzERvdMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgUJizgSs_1g"
      },
      "source": [
        "## Gerekli paketlerimizi import edelim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rrA1Kt8Fs_1h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be8F_hdls_1i"
      },
      "source": [
        "## Ayarlar ve hiperparametreler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2O-Hhoqds_1i"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "BATCH_SIZE = 64\n",
        "SEQ_LEN = 128\n",
        "MIN_TRAINING_SEQ_LEN = 450\n",
        "\n",
        "# Model\n",
        "EMBED_DIM = 256\n",
        "FEED_FORWARD_DIM = 256\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 2\n",
        "VOCAB_SIZE = 5000  #Modeldeki parametreleri sınırlar.\n",
        "\n",
        "# Eğitim\n",
        "EPOCHS = 6\n",
        "\n",
        "# Çıkarım\n",
        "NUM_TOKENS_TO_GENERATE = 80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KygeWfJCs_1i"
      },
      "source": [
        "## Data'yı yükleyelim.\n",
        "\n",
        "Şimdi veri setini indirelim. SimpleBooks veri seti 1.573 Gutenberg kitabından oluşur ve\n",
        "kelime düzeyinde belirteç oranına en küçük kelime boyutundan biri, ~98k kelime dağarcığı boyutuna sahiptir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TmRKJDNfs_1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18394c9-ebb3-4f34-a05f-98c845c8aaa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\n",
            "282386239/282386239 [==============================] - 10s 0us/step\n"
          ]
        }
      ],
      "source": [
        "keras.utils.get_file(\n",
        "    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "dir = os.path.expanduser(\"~/.keras/datasets/simplebooks/\")\n",
        "\n",
        "# simplebooks-92 train setini yükleyin ve kısa satırları filtreleyin.\n",
        "raw_train_ds = (\n",
        "    tf.data.TextLineDataset(dir + \"simplebooks-92-raw/train.txt\")\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(buffer_size=256)\n",
        ")\n",
        "\n",
        "# simplebooks-92 doğrulama setini yükleyin ve kısa satırları filtreleyin.\n",
        "raw_val_ds = (\n",
        "    tf.data.TextLineDataset(dir + \"simplebooks-92-raw/valid.txt\")\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf5IW9q-s_1j"
      },
      "source": [
        "## Tokenizer'ı eğitelim\n",
        "\n",
        "Tokenizerı, \"VOCAB_SIZE\" kelime dağarcığı boyutu için eğitim veri kümesinden eğitiyoruz,\n",
        "\"VOCAB_SIZE\" yukarıda ayarlamış olduğumuz bir hiperparametredir. Kelime dağarcığını mümkün olduğunca sınırlamak istiyoruz, çünkü model parametre sayısı üzerinde büyük bir etkisi vardır.\n",
        "\n",
        "- `\"[PAD]\"` kısa cümlelerin sonuna ya da başına varsayılan olarak 0 rakamı eklenir ki modele girecek olan cümlenin boyutunu aynı tutalım.\n",
        "\n",
        "- `\"[UNK]\"` varsayılanla eşleşmesi gereken OOV alt sözcükleri için `oov_token=\"[UNK]\"`\n",
        "\n",
        "- `\"[BOS]\"` cümlenin başlangıcı anlamına gelir,\n",
        "eğitim verilerinin her satırının başlangıcını temsil eder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IMefQVghs_1k"
      },
      "outputs": [],
      "source": [
        "# Train tokenizer vocabulary\n",
        "vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "    raw_train_ds,\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    lowercase=True,\n",
        "    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAgj-0sDs_1k"
      },
      "source": [
        "## Tokenizer'ı yükleyelim\n",
        "\n",
        "`keras_nlp.tokenizers.WordPieceTokenizer` kullanarak WordPieceTokenizer'ı başlatabiliriz. Bu paket\n",
        "BERT ve diğer modeller tarafından kullanılan WordPiece algoritmasının uygulanmasıdır. Verimli şekilde metin ön işleme yapabiliriz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8W7n8xTJs_1k"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    lowercase=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WenNanLis_1k"
      },
      "source": [
        "## Tokenize Verisini ayarlıyoruz. ( özellik ve etiketi şeklinde )\n",
        "\n",
        "Veri kümesini belirteç haline getirerek ve onu `features` ve `labels` olarak bölerek önceden işleriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dAsAQo2Us_1l"
      },
      "outputs": [],
      "source": [
        "# paketleyici bir başlangıç belirteci ekler\n",
        "start_packer = keras_nlp.layers.StartEndPacker(\n",
        "    sequence_length=SEQ_LEN,\n",
        "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess(inputs):\n",
        "    outputs = tokenizer(inputs)\n",
        "    features = start_packer(outputs)\n",
        "    labels = outputs\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# Tokenize edin ve train ve label dizilerine bölün.\n",
        "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")\n",
        "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUZSSQS_s_1l"
      },
      "source": [
        "## Modelimizin İnşaası\n",
        "\n",
        "Aşağıdaki katmanlarla küçültülmüş GPT modelimizi oluşturuyoruz:\n",
        "\n",
        "- Token ve konumu için gömme matrisini içinde tutan bir adet `keras_nlp.layers.TokenAndPositionEmbedding` katmanı.\n",
        "- Varsayılan nedensel maskeleme ile birden çok `keras_nlp.layers.TransformerDecoder` katmanı.\n",
        "Katman, yalnızca kod çözücü dizisiyle çalıştırıldığında çapraz dikkat göstermez.\n",
        "- Son bir yoğun doğrusal katman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "72H6ioPms_1l"
      },
      "outputs": [],
      "source": [
        "inputs = keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
        "# Embedding.\n",
        "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")\n",
        "x = embedding_layer(inputs)\n",
        "# Transformer decoders.\n",
        "for _ in range(NUM_LAYERS):\n",
        "    decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
        "        num_heads=NUM_HEADS,\n",
        "        intermediate_dim=FEED_FORWARD_DIM,\n",
        "    )\n",
        "    x = decoder_layer(x)  # Tek bir argüman vermek, yalnızca çapraz ilgiyi atlar.\n",
        "# Çıkış.\n",
        "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
        "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[perplexity])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hKeZUeUs_1m"
      },
      "source": [
        "Model özetimize bir göz atalım. \n",
        "Parametrelerin büyük çoğunluğu token_and_position_embedding ve çıktı katmanındadır! Bu, kelime boyutunun (VOCAB_SIZE) modelin boyutu üzerinde büyük bir etkiye sahip olduğu, ancak Transformer kod çözücü katmanlarının (NUM_LAYERS) sayısının onu çok fazla etkilemediği anlamına gelir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qhBsF5ZVs_1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab349c0-096a-4c7f-effb-06fda95f28b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 256)        1312768   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " transformer_decoder (Transf  (None, None, 256)        394749    \n",
            " ormerDecoder)                                                   \n",
            "                                                                 \n",
            " transformer_decoder_1 (Tran  (None, None, 256)        394749    \n",
            " sformerDecoder)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 5000)        1285000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,387,266\n",
            "Trainable params: 3,387,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE3ojJ9ps_1m"
      },
      "source": [
        "## Eğitim\n",
        "\n",
        "Artık modelimize sahip olduğumuza göre, onu fit() metodu ile eğitelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iTSFn1u8s_1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606b2239-9abf-4098-8f6e-89a6b10a9f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "3169/3169 - 403s - loss: 4.5896 - perplexity: 98.8414 - val_loss: 4.1571 - val_perplexity: 64.4688 - 403s/epoch - 127ms/step\n",
            "Epoch 2/6\n",
            "3169/3169 - 250s - loss: 4.0607 - perplexity: 58.2387 - val_loss: 3.9988 - val_perplexity: 55.0357 - 250s/epoch - 79ms/step\n",
            "Epoch 3/6\n",
            "3169/3169 - 248s - loss: 3.9406 - perplexity: 51.6441 - val_loss: 3.9409 - val_perplexity: 51.9935 - 248s/epoch - 78ms/step\n",
            "Epoch 4/6\n",
            "3169/3169 - 244s - loss: 3.8762 - perplexity: 48.4238 - val_loss: 3.8679 - val_perplexity: 48.3114 - 244s/epoch - 77ms/step\n",
            "Epoch 5/6\n",
            "3169/3169 - 239s - loss: 3.8314 - perplexity: 46.2981 - val_loss: 3.8806 - val_perplexity: 48.8037 - 239s/epoch - 76ms/step\n",
            "Epoch 6/6\n",
            "3169/3169 - 240s - loss: 3.7978 - perplexity: 44.7659 - val_loss: 3.8226 - val_perplexity: 46.1492 - 240s/epoch - 76ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8d84c82e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.fit(train_ds, validation_data=val_ds, verbose=2, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq2c9fxgs_1m"
      },
      "source": [
        "## Çıkarım\n",
        "\n",
        "Eğitimli modelimizin performansını ölçmek için test edebiliriz. Çünkü bu model\n",
        "`\"[BOS]\"` belirteci ile oluşturulmuş, metin oluşturma için boş bir başlangıç istemimiz olabilir. Bu durumu istemeyiz. Kontrol edelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YosTKt6Ws_1m"
      },
      "outputs": [],
      "source": [
        "# Doldurulmamış bos belirteci.\n",
        "prompt_tokens = tf.convert_to_tensor([tokenizer.token_to_id(\"[BOS]\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7FVpRP4s_1n"
      },
      "source": [
        "Çıkarım için `keras_nlp.utils` modülünü kullanacağız. Her metin üretimi model etrafında bir \"token_logits_fn()\" sarmalayıcı gerektirir. Bu sarmalayıcı dolgusuz bir belirteç dizisinde ve çıktı olarak bir sonraki belirtecin logitlerini gerektirir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-rE0WCNVs_1n"
      },
      "outputs": [],
      "source": [
        "\n",
        "def token_logits_fn(inputs):\n",
        "    cur_len = inputs.shape[1]\n",
        "    output = model(inputs)\n",
        "    return output[:, cur_len - 1, :]  # sonraki tokenleri döndür.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW-sKQSIs_1n"
      },
      "source": [
        "Sarmalayıcı işlevini oluşturmak, bu işlevleri kullanmanın en karmaşık kısmıdır. Artık bittiğine göre, açgözlü aramayla başlayarak farklı araçları test edelim."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Üretilen çıktıları hangi mantıkla seçeceğiz, farklı arama ve seçim yöntemleri vardır. Bir kısmına göz atalım."
      ],
      "metadata": {
        "id": "p_br9-N32szf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVkMn5vrs_1n"
      },
      "source": [
        "### Greedy search\n",
        "\n",
        "Her zaman adımında en olası tokenleri açgözlülükle seçiyoruz. Başka bir deyişle, model çıktısının argmax'ını elde ederiz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uTnOo1his_1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd72d2b2-2c14-4a84-cac5-5c41f90864ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Açgözlü arama oluşturulan metin: \n",
            "b'[BOS] \" i \\' m not going to be a good man , \" he said . \" i \\' m not going to be a good man , and i \\' m not going to be a man , and i \\' m going to be a man , and i \\' m going to be a man , and i \\' m going to be a man , and i \\' m going to be a man ,'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_tokens = keras_nlp.utils.greedy_search(\n",
        "    token_logits_fn,\n",
        "    prompt_tokens,\n",
        "    max_length=NUM_TOKENS_TO_GENERATE,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Açgözlü arama oluşturulan metin: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfclzqsAs_1n"
      },
      "source": [
        "Gördüğünüz gibi, açgözlü arama bir anlam ifade etmeye başlar, ancak hızla kendini tekrar etmeye başlar.\n",
        "Bu, bazı yazılımlar tarafından düzeltilebilen metin oluşturma ile ilgili yaygın bir sorundur.\n",
        "Olasılıksal metin oluşturma yardımcı programları daha sonra gösterilecektir!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oszAdHzs_1n"
      },
      "source": [
        "### Beam search\n",
        "\n",
        "Yüksek düzeyde ışın araması en olası dizilerin \"num_beams\" izini tutar.\n",
        "Her zaman adımı ve tüm dizilerden bir sonraki en iyi tokeni tahmin eder.\n",
        "\n",
        "Aç gözlü aramaya göre daha gelişmiştir ancak birden fazla olasılığı hesaplayıp tuttuğu için bellek ve hız açısından dejavantaj sunar.\n",
        "\n",
        "**Not:** `num_beams=1` ayarını beam_search de ayarlarsak, açgözlü aramayla aynı işi yapmış oluruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "paAeG7C4s_1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd19015-2642-4704-9ca3-601976e239b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam search ile oluşturulan metin: \n",
            "b'[BOS] \" i don \\' t know , \" he said . \" i don \\' t know what to do , \" he said . \" i don \\' t know what to do , but i don \\' t know what to do . i don \\' t know what to do . i don \\' t know what to do , but i don \\' t know what to do , and i don \\' t know'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_tokens = keras_nlp.utils.beam_search(\n",
        "    token_logits_fn,\n",
        "    prompt_tokens,\n",
        "    max_length=NUM_TOKENS_TO_GENERATE,\n",
        "    num_beams=10,\n",
        "    from_logits=True,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Beam search ile oluşturulan metin: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynzoBFjis_1o"
      },
      "source": [
        "Aç gözlü arama gibi ışın araması hızla kendini tekrar etmeye başlar, çünkü hala\n",
        "deterministik bir yöntem.\n",
        "`Deterministik yöntem demek` sistemin gelecekteki durumlarının gelişmesinde rastgelelik bulunmayan bir sistem demektir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMiiY8FEs_1o"
      },
      "source": [
        "### Random search\n",
        "\n",
        "Rastgele arama, ilk olasılıksal yöntemimizdir. Her zaman adımında, bir sonrakini örnekler\n",
        "model tarafından sağlanan softmax olasılıklarını kullanarak belirlenir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "x5MKh2RTs_1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0e9eba-43b3-4c4b-bdad-0f000f01d19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random search ile üretilen metin: \n",
            "b'[BOS] edgar collector reperfusive the twosters number two of his best friends to close friends . a second lieutenant was taken suddenly an immense number of doubt . the distance was small , and grace had arranged it must be very pledge that she might for some purpose ; at any rate she would startle forward at once , because it would cost much if possible position ,'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_tokens = keras_nlp.utils.random_search(\n",
        "    token_logits_fn,\n",
        "    prompt_tokens,\n",
        "    max_length=NUM_TOKENS_TO_GENERATE,\n",
        "    from_logits=True,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Random search ile üretilen metin: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXa1INxBs_1p"
      },
      "source": [
        "Vay!, tekrar yok! Ancak, rastgele arama ile, bu örnekleme yöntemiyle kelime dağarcığındaki herhangi bir kelimenin çıkma şansı olduğundan, bazı anlamsız kelimelerin ortaya çıktığını görebiliriz. Bu, bir sonraki arama yardımcı programımız olan top-k search ile düzeltilebilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjjcpMQFs_1p"
      },
      "source": [
        "### Top-K search\n",
        "\n",
        "Rastgele aramaya benzer şekilde, model tarafından sağlanan olasılık dağılımından bir sonraki tokenleri tahminliyoruz. Tek fark, burada en olası k belirteci seçip örneklemeden önce olasılık kütlesini bunların üzerine dağıtmamızdır. Bu şekilde, düşük olasılıklı belirteçlerden örnekleme yapmayacağız ve bu nedenle daha az saçma kelimemiz olacak :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3XwDSqros_1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8e6784-4097-4bbc-be76-7056d69e94f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-K search ile üretilen metin: \n",
            "b'[BOS] \" the first thing is to go on , \" she remarked , and her voice was peering through the glass . \" when the girls came down to her house , she told her of a great crowd of men , but she had not been away to a moment , and had she been so long approved . she had heard nothing to do , and she had never heard of such a word'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_tokens = keras_nlp.utils.top_k_search(\n",
        "    token_logits_fn,\n",
        "    prompt_tokens,\n",
        "    max_length=NUM_TOKENS_TO_GENERATE,\n",
        "    k=10,\n",
        "    from_logits=True,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-K search ile üretilen metin: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDDOahT2s_1q"
      },
      "source": [
        "### Top-P search\n",
        "\n",
        "En iyi aramada bile geliştirilecek bir şeyler var. Top-k arama ile k sayısı sabittir, yani herhangi bir olasılık dağılımı için aynı sayıda belirteci seçer. Biri olasılık kütlesinin 2 kelime üzerinde yoğunlaştığı, diğeri ise olasılık kütlesinin eşit olarak 10 kelime üzerinde yoğunlaştığı iki senaryo düşünün. k=2'yi mi yoksa k=10'u mu seçmeliyiz? Burada her ikisine uyan bir değer yok. Ne yapmalıyız ?\n",
        "\n",
        "Üst düzey aramanın devreye girdiği yer burasıdır! Bir k seçmek yerine, en iyi belirteçlerin olasılıklarının toplanmasını istediğimiz bir p olasılığı seçiyoruz. Bu şekilde, k'yi olasılık dağılımına göre dinamik olarak ayarlayabiliriz. p=0.9'u ayarlayarak, olasılık kütlesinin %90'ı ilk 2 belirteç üzerinde yoğunlaşırsa, örnek alınacak ilk 2 belirteci filtreleyebiliriz. Bunun yerine %90, 10 jetona dağıtılırsa, benzer şekilde örnek alınacak ilk 10 jetonu filtreleyecektir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-CxKNsDOs_1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176dd7a0-2c8b-47d2-b7d2-6a8eb3ab4c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-P search ile üretilen metin: \n",
            "b'[BOS] \" why should we go with you ? \" he said . \" i am very much afraid of being confirmitted , and if you are to be taken out of the city , it is impossible to take you into the town . it would be very hard to find fault , and would have made you feel so ashamed , that you would have been much better than you would have been'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_tokens = keras_nlp.utils.top_p_search(\n",
        "    token_logits_fn,\n",
        "    prompt_tokens,\n",
        "    max_length=NUM_TOKENS_TO_GENERATE,\n",
        "    p=0.5,\n",
        "    from_logits=True,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-P search ile üretilen metin: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afB8aSozs_1q"
      },
      "source": [
        "### Metin oluşturmak için callbacks'leri kullanma\n",
        "\n",
        "Yardımcı programları, bir tahminin çıktısını almanıza izin veren bir geri aramaya da sarabiliriz.İşte en iyi k araması için bir callbacks örneği:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VtZ_XpSMs_1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8669a919-14de-45bc-d324-b337d20c3f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "Top-K search üretilen metin: \n",
            "b'[BOS] \" i was not at present , \" the captain replied . \" if the men could not have had the slightest chance of obtaining , the captain would , as they did , if the boat had been affected by a slight shock . but , in the morning i should have taken up his position , and as i have no doubt that he was a prisoner , and i should have no'\n",
            "\n",
            "1/1 - 10s - loss: 3.8801 - perplexity: 48.5693 - 10s/epoch - 10s/step\n",
            "Epoch 2/2\n",
            "Top-K search üretilen metin: \n",
            "b'[BOS] \" yes , \" answered the guide , but it is only possible that the guide \\' s trail is the way in that direction is not so wide - awake . the road is a mile or so . i donned the track by track and passing along the trail of the path by a path leading down the path , and when i saw it was a short one , and i heard the noise that'\n",
            "\n",
            "1/1 - 9s - loss: 3.8640 - perplexity: 47.7789 - 9s/epoch - 9s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8d8208b20>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "class TopKTextGenerator(keras.callbacks.Callback):\n",
        "    \"\"\"top-k Kullanarak eğitilmiş bir modelden metin oluşturmak için bir callbacks\"\"\"\n",
        "\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        output_tokens = keras_nlp.utils.top_k_search(\n",
        "            token_logits_fn,\n",
        "            prompt_tokens,\n",
        "            max_length=NUM_TOKENS_TO_GENERATE,\n",
        "            k=self.k,\n",
        "            from_logits=True,\n",
        "        )\n",
        "        txt = tokenizer.detokenize(output_tokens)\n",
        "        print(f\"Top-K search üretilen metin: \\n{txt}\\n\")\n",
        "\n",
        "\n",
        "text_generation_callback = TopKTextGenerator(k=10)\n",
        "# Geri aramayı göstermek için dummy train döngüsü.\n",
        "model.fit(train_ds.take(1), verbose=2, epochs=2, callbacks=[text_generation_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vud2Mda2s_1r"
      },
      "source": [
        "## Özet\n",
        "\n",
        "Özetlemek gerekirse, bu örnekte, bir kelime sözlüğünü eğitmek için KerasNLP katmanlarını kullanıyoruz.\n",
        "\n",
        "Eğitim verilerini tokenize ettik, minyatür bir GPT modeli oluşturduk ve\n",
        "metin oluşturma kitaplığını kullandık.\n",
        "\n",
        "Transformers'ın nasıl çalıştığını anlamak veya Transformers'ı eğitmek hakkında daha fazla bilgi edinmek istiyorsanız,\n",
        "\n",
        "- [Vaswani ve diğerleri, 2017](https://arxiv.org/abs/1706.03762)\n",
        "- GPT-3 Raporu [Brown ve diğerleri, 2020](https://arxiv.org/abs/2005.14165)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}